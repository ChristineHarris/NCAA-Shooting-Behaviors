{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ST446 Distributed Computing for Big Data\n",
    "## Homework PART 1\n",
    "---\n",
    "\n",
    "\n",
    "## P1: Querying the YAGO semantic knowledge base\n",
    "\n",
    "YAGO is a semantic knowledge base, derived from Wikipedia, WordNet and GeoNames. YAGO contains knowledge about more than 10 million entities (like persons, organizations and cities) and contains more than 120 million facts about these entities. You may find more about YAGO [here](https://www.mpi-inf.mpg.de/departments/databases-and-information-systems/research/yago-naga/yago/#c10444).\n",
    "\n",
    "*You may use GCP or your own computer. Please document your steps. We highly recommend using GCP, as the data sets used are about 20 GB in total.*\n",
    "\n",
    "In this homework assignment, you are asked to use parts of the YAGO dataset to demonstrate your knowledge about Spark graphframes and motif queries. In particular, you are asked to **_use motif queries_** to find out answers to the following queries stated in English:\n",
    "\n",
    "**A (max points 0)**. _Which city was Albert Einstein born in?_ \n",
    "\n",
    "**B (max points 5)**. _Politicians who are also scientists_ (sorted alphabetically by name of person)\n",
    "\n",
    "**C (max points 5)**. _Companies whose founders were born in London_ (sorted alphabetically by name of founder)\n",
    "\n",
    "**D (max points 5)**. _Writers who have won a Nobel Prize (in any discipline)_ (sorted alphabetically by name of person)\n",
    "\n",
    "**E (max points 5)**. _Nobel prize winners who were born in the same city as their spouses_ (sorted alphabetically by name of person)\n",
    "\n",
    "**F (max points 5)**. _Politicians that are affiliated with a right-wing party_ (sorted alphabetically by name of person)\n",
    "\n",
    "Please always show the first 20 entries of the resulting DataFrame and the total count of relevant entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Get YAGO data\n",
    "\n",
    "You will need to download the following datasets that are part of YAGO (see [here](https://www.mpi-inf.mpg.de/departments/databases-and-information-systems/research/yago-naga/yago/downloads/) for more information):\n",
    "\n",
    "* A set of relationships between instances (for example, specifying that Emomali Rahmon is the leader of the Military of Tajikistan). Link: http://resources.mpi-inf.mpg.de/yago-naga/yago3.1/yagoFacts.tsv.7z\n",
    "\n",
    "* A set of subclass relationships (for example, specifying that *A1086* is *a road in England*, or that *Salmonella Dub* is *a Reggae music group* and also a *New Zealand dub musical group*). Link: http://resources.mpi-inf.mpg.de/yago-naga/yago3.1/yagoTransitiveType.tsv.7z\n",
    "\n",
    "Please use `wget` to download the data to your compute engine (the files are big!).\n",
    "\n",
    "Next, you will need extract `tsv` files from the `7z` archives that you have downloaded.\n",
    "Use the following commands to install `p7zip` on your compute engine and extract the files.\n",
    "```\n",
    "sudo apt-get install p7zip-full\n",
    "7z x yagoTransitiveType.tsv.7z \n",
    "7z x yagoFacts.tsv.7z \n",
    "```\n",
    "Please note that this can take a while, in particular as `yagoTransitiveType.tsv` is **18GB** large.\n",
    "\n",
    "Put the files (`yagoTransitiveType.tsv` and `yagoFacts.tsv`) into the hadoop file system. \n",
    "Also, have a look at their first few lines to understand what kind of data they contain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation of Initial Steps\n",
    "\n",
    "First, I open a command prompt window and set up a dataproc cluster `christine-cluster` using the following command:\n",
    "\n",
    "```\n",
    "C:\\Users\\44738>gcloud dataproc clusters create christine-cluster --project seminar-4 --properties=^^^^#^^^^spark:spark.jars.packages=graphframes:graphframes:0.5.0-spark2.1-s_2.11,com.databricks:spark-csv_2.11:1.5.0 --subnet default --zone europe-west2-a --master-machine-type n1-standard-4 --master-boot-disk-size 500 --num-workers 2 --worker-machine-type n1-standard-4 --worker-boot-disk-size 500 --image-version 1.3-deb9  --initialization-actions \"gs://dataproc-initialization-actions/jupyter/jupyter.sh\",\"gs://dataproc-initialization-actions/python/pip-install.sh\",\"gs://dataproc-initialization-actions/zookeeper/zookeeper.sh\",\"gs://dataproc-initialization-actions/kafka/kafka.sh\" --metadata \"PIP_PACKAGES=sklearn nltk pandas graphframes\"\n",
    "Waiting on operation [projects/seminar-4/regions/europe-west2/operations/e1768ca7-97d7-3509-93ae-0569a7524431].\n",
    "Waiting for cluster creation operation...\n",
    "WARNING: For PD-Standard without local SSDs, we strongly recommend provisioning 1TB or larger to ensure consistently high I/O performance. See https://cloud.google.com/compute/docs/disks/performance for information on disk I/O performance.\n",
    "Waiting for cluster creation operation...done.\n",
    "Created [https://dataproc.googleapis.com/v1/projects/seminar-4/regions/europe-west2/clusters/christine-cluster] Cluster placed in zone [europe-west2-a].\n",
    "```\n",
    "\n",
    "Next, I open the hdfs master node using the following command:\n",
    "\n",
    "```\n",
    "C:\\Users\\44738>gcloud beta compute --project \"seminar-4\" ssh --zone \"europe-west2-a\" \"christine-cluster-m\" \n",
    "```\n",
    "\n",
    "In the hdfs master node, I use the `wget` command to download both tsv files:\n",
    "\n",
    "```\n",
    "44738@christine-cluster-m:~$ wget http://resources.mpi-inf.mpg.de/yago-naga/yago                                                                             3.1/yagoFacts.tsv.7z\n",
    "--2020-03-18 21:37:32--  http://resources.mpi-inf.mpg.de/yago-naga/yago3.1/yagoF                                                                             acts.tsv.7z\n",
    "Resolving resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)... 139.19.206.46\n",
    "Connecting to resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)|139.19.206.46|                                                                             :80... connected.\n",
    "HTTP request sent, awaiting response... 200 OK\n",
    "Length: 240204435 (229M) [application/x-7z-compressed]\n",
    "Saving to: ‘yagoFacts.tsv.7z’\n",
    "\n",
    "yagoFacts.tsv.7z    100%[===================>] 229.08M  93.8MB/s    in 2.4s\n",
    "\n",
    "2020-03-18 21:37:34 (93.8 MB/s) - ‘yagoFacts.tsv.7z’ saved [240204435/240204435]\n",
    "\n",
    "44738@christine-cluster-m:~$ wget http://resources.mpi-inf.mpg.de/yago-naga/yago                                                                             3.1/yagoTransitiveType.tsv.7z\n",
    "--2020-03-18 21:37:44--  http://resources.mpi-inf.mpg.de/yago-naga/yago3.1/yagoT                                                                             ransitiveType.tsv.7z\n",
    "Resolving resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)... 139.19.206.46\n",
    "Connecting to resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)|139.19.206.46|                                                                             :80... connected.\n",
    "HTTP request sent, awaiting response... 200 OK\n",
    "Length: 1813458594 (1.7G) [application/x-7z-compressed]\n",
    "Saving to: ‘yagoTransitiveType.tsv.7z’\n",
    "\n",
    "yagoTransitiveType. 100%[===================>]   1.69G  93.6MB/s    in 18s\n",
    "\n",
    "2020-03-18 21:38:02 (97.8 MB/s) - ‘yagoTransitiveType.tsv.7z’ saved [1813458594/                                                                             1813458594]\n",
    "\n",
    "```\n",
    "\n",
    "Still in the master node, I extract both tsv files according to the directions given above:\n",
    "\n",
    "```\n",
    "44738@christine-cluster-m:~$ sudo apt-get install p7zip-full\n",
    "Reading package lists... Done\n",
    "Building dependency tree\n",
    "Reading state information... Done\n",
    "The following additional packages will be installed:\n",
    "  p7zip\n",
    "Suggested packages:\n",
    "  p7zip-rar\n",
    "The following NEW packages will be installed:\n",
    "  p7zip p7zip-full\n",
    "0 upgraded, 2 newly installed, 0 to remove and 3 not upgraded.\n",
    "Need to get 1,479 kB of archives.\n",
    "After this operation, 5,469 kB of additional disk space will be used.\n",
    "Do you want to continue? [Y/n] y\n",
    "Get:1 http://deb.debian.org/debian stretch/main amd64 p7zip amd64 16.02+dfsg-3+d                                                                             eb9u1 [364 kB]\n",
    "Get:2 http://deb.debian.org/debian stretch/main amd64 p7zip-full amd64 16.02+dfs                                                                             g-3+deb9u1 [1,115 kB]\n",
    "Fetched 1,479 kB in 0s (17.5 MB/s)\n",
    "Selecting previously unselected package p7zip.\n",
    "(Reading database ... 142916 files and directories currently installed.)\n",
    "Preparing to unpack .../p7zip_16.02+dfsg-3+deb9u1_amd64.deb ...\n",
    "Unpacking p7zip (16.02+dfsg-3+deb9u1) ...\n",
    "Selecting previously unselected package p7zip-full.\n",
    "Preparing to unpack .../p7zip-full_16.02+dfsg-3+deb9u1_amd64.deb ...\n",
    "Unpacking p7zip-full (16.02+dfsg-3+deb9u1) ...\n",
    "Setting up p7zip (16.02+dfsg-3+deb9u1) ...\n",
    "Processing triggers for man-db (2.7.6.1-2) ...\n",
    "Setting up p7zip-full (16.02+dfsg-3+deb9u1) ...\n",
    "\n",
    "44738@christine-cluster-m:~$ 7z x yagoTransitiveType.tsv.7z\n",
    "\n",
    "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
    "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,4 CPUs Int                                                                             el(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
    "\n",
    "Scanning the drive for archives:\n",
    "1 file, 1813458594 bytes (1730 MiB)\n",
    "\n",
    "Extracting archive: yagoTransitiveType.tsv.7z\n",
    "--\n",
    "Path = yagoTransitiveType.tsv.7z\n",
    "Type = 7z\n",
    "Physical Size = 1813458594\n",
    "Headers Size = 148\n",
    "Method = LZMA:24\n",
    "Solid = -\n",
    "Blocks = 1\n",
    "\n",
    "Everything is Ok\n",
    "\n",
    "Size:       18390277560\n",
    "Compressed: 1813458594\n",
    "\n",
    "44738@christine-cluster-m:~$ 7z x yagoFacts.tsv.7z\n",
    "\n",
    "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
    "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,4 CPUs Int                                                                             el(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
    "\n",
    "Scanning the drive for archives:\n",
    "1 file, 240204435 bytes (230 MiB)\n",
    "\n",
    "Extracting archive: yagoFacts.tsv.7z\n",
    "--\n",
    "Path = yagoFacts.tsv.7z\n",
    "Type = 7z\n",
    "Physical Size = 240204435\n",
    "Headers Size = 129\n",
    "Method = LZMA:24\n",
    "Solid = -\n",
    "Blocks = 1\n",
    "\n",
    "Everything is Ok\n",
    "\n",
    "Size:       1019693498\n",
    "Compressed: 240204435\n",
    "```\n",
    "\n",
    "Then, I move both files into the hadoop file system:\n",
    "\n",
    "```\n",
    "44738@christine-cluster-m:~$ hadoop fs -ls /\n",
    "Found 3 items\n",
    "drwx------   - mapred hadoop          0 2020-03-18 21:34 /hadoop\n",
    "drwxrwxrwt   - hdfs   hadoop          0 2020-03-18 21:34 /tmp\n",
    "drwxrwxrwt   - hdfs   hadoop          0 2020-03-18 21:33 /user\n",
    "\n",
    "44738@christine-cluster-m:~$ hadoop fs -mkdir /user/root\n",
    "\n",
    "44738@christine-cluster-m:~$ hadoop fs -put yagoFacts.tsv /user/root/\n",
    "\n",
    "44738@christine-cluster-m:~$ hadoop fs -put yagoTransitiveType.tsv /user/root/\n",
    "\n",
    "44738@christine-cluster-m:~$ hadoop fs -ls /user/root\n",
    "Found 2 items\n",
    "-rw-r--r--   2 44738 hadoop  1019693498 2020-03-19 18:30 /user/root/yagoFacts.tsv\n",
    "-rw-r--r--   2 44738 hadoop 18390277560 2020-03-19 18:33 /user/root/yagoTransitiveType.tsv\n",
    "\n",
    "```\n",
    "\n",
    "I also took a look at both files to get a sense of what kind of data they contain.\n",
    "\n",
    "```\n",
    "44738@christine-cluster-m:~$ head yagoFacts.tsv\n",
    "        <yagoTheme_yagoFacts>   <hasGloss>      \"This file is part of the ontology YAGO3. It is licensed under a Creative-Commons Attribution License by the YAGO team at the Max Planck Institute for Informatics/Germany. See http://yago-knowledge.org for all details. This file was generated on 2017-06-19 T 08:01:29.0836. All facts of YAGO that hold between instances CORE\"\n",
    "<id_rB6isMnplh_H?S_LT?Qo1Fzc!>  <Jesús_Rivera_Sánchez>  <isLeaderOf>    <Pueblo_of_Naranjito>\n",
    "<id_BOK!FvTDPu_H?S_1NVSTKkFbS>  <Elizabeth_II>  <isLeaderOf>    <Royal_Numismatic_Society>\n",
    "<id_Uy5EwU3nX1_H?S_otuJrkvKs1>  <Richard_Stallman>      <isLeaderOf>    <Free_Software_Foundation>\n",
    "<id_A?rIHtKpyX_H?S_Ap3TBzfE6b>  <Keith_Peterson>        <isLeaderOf>    <Cambridge_Bay>\n",
    "<id_vzhzgmCR5Y_H?S_9xW07qYiaH>  <William_H._Seward_Jr.> <isLeaderOf>    <9th_New_York_Heavy_Artillery_Regiment>\n",
    "<id_GqUh9jFAN?_H?S_A39fu5FWu4>  <Andranik>      <isLeaderOf>    <Armenian_fedayi>\n",
    "<id_s60Psk1DHb_H?S_OACCn8W8Kv>  <Ramasamy_Palanisamy>   <isLeaderOf>    <Democratic_Action_Party_(Malaysia)>\n",
    "<id_pII60Mnz8o_H?S_8mvRWxKXDG>  <Matt_Bevin>    <isLeaderOf>    <Kentucky_Air_National_Guard>\n",
    "<id_losV58WRWE_H?S_KxmZk2LtbV>  <Leonard_Leo>   <isLeaderOf>    <Federalist_Society>\n",
    "\n",
    "44738@christine-cluster-m:~$ head yagoTransitiveType.tsv\n",
    "        <yagoTheme_yagoTransitiveType>  <hasGloss>      \"This file is part of the ontology YAGO3. It is licensed under a Creative-Commons Attribution License by the YAGO team at the Max Planck Institute for Informatics/Germany. See http://yago-knowledge.org for all details. This file was generated on 2017-06-06 T 18:48:11.0135. Transitive closure of all rdf:type/rdfs:subClassOf facts TAXONOMY\"\n",
    "<id_IDwmgVA9s0_KCM_rINXattJoD>  <1908_St._Louis_Browns_season>  rdf:type        <wikicat_Baltimore_Orioles_seasons>\n",
    "<id_IDwmgVA9s0_KCM_w?uK7?WKJH>  <1908_St._Louis_Browns_season>  rdf:type        <wikicat_Major_League_Baseball_teams_seasons>\n",
    "<id_IDwmgVA9s0_KCM_FyppX?MtG?>  <1908_St._Louis_Browns_season>  rdf:type        <wikicat_St._Louis_Browns_seasons>\n",
    "<id_IDwmgVA9s0_KCM_2JNSaunrSx>  <1908_St._Louis_Browns_season>  rdf:type        <wordnet_abstraction_100002137>\n",
    "<id_IDwmgVA9s0_KCM_M8v8FgA!sO>  <1908_St._Louis_Browns_season>  rdf:type        <wordnet_fundamental_quantity_113575869>\n",
    "<id_IDwmgVA9s0_KCM_G!H3S90mJ0>  <1908_St._Louis_Browns_season>  rdf:type        <wordnet_measure_100033615>\n",
    "<id_IDwmgVA9s0_KCM_Zlk4NLDCV7>  <1908_St._Louis_Browns_season>  rdf:type        <wordnet_season_115239579>\n",
    "<id_IDwmgVA9s0_KCM_xxJUNq6YUn>  <1908_St._Louis_Browns_season>  rdf:type        <wordnet_time_period_115113229>\n",
    "<id_IDwmgVA9s0_KCM_KdEX!y?wiG>  <1908_St._Louis_Browns_season>  rdf:type        owl:Thing\n",
    "```\n",
    "\n",
    "Once I have both of my files ready, I proceed to open a PySpark notebook. To do this, I go into Google Cloud Platform and navigate to `Dataproc -> Clusters`, select `christine-cluster`, select `Web Interfaces` and then `Create an SSH tunnel to connect to a web interface`. I use the command given in a second command prompt window:\n",
    "\n",
    "```\n",
    "C:\\Users\\44738>gcloud compute ssh christine-cluster-m --project=seminar-4 --zone=europe-west2-a -- -D 1080 -N\n",
    "```\n",
    "\n",
    "In a third command prompt window, I open a new chrome tab by typing the following:\n",
    "\n",
    "```\n",
    "C:\\Users\\44738>cd C:\\Program Files (x86)\\Google\\Chrome\\Application\n",
    "\n",
    "C:\\Program Files (x86)\\Google\\Chrome\\Application>chrome.exe --proxy-server=\"socks5://localhost:1080\" --user-data-dir=\"%Temp%\\christine-cluster-m\" http://christine-cluster-m:8123\n",
    "```\n",
    "\n",
    "I then proceed to open a new PySpark notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Read the data into a Spark DataFrame\n",
    "\n",
    "Please load the data from `yagoFacts.tsv` into a DataFrame called `df` and `yagoTransitiveType.tsv` into a DataFrame called `df_subclasses`.\n",
    "Have a look at the beginning of the files to understand the schema.\n",
    "Once imported, both DataFrames should have columns labelled as `id`, `subject`, `predicate`, `object` and `value`.\n",
    "In the case of `yagoTransitiveType.tsv`, some of the predicates can be understood as *\"is a sublcass of\"* or *\"is member of the class\"*, and the objects can be understood as classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from graphframes import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Set fpath to the location of the data\n",
    "fpath = \"hdfs://christine-cluster-m/user/root/\"\n",
    "\n",
    "# Write a function 'load_tsv' to read in the data\n",
    "def load_tsv(tsv_name):\n",
    "    \n",
    "    # Both DFs have columns id, subject, predicate, object and value\n",
    "    schema = StructType([\n",
    "        StructField(\"id\", StringType(), True),    \n",
    "        StructField(\"subject\", StringType(), True),\n",
    "        StructField(\"predicate\", StringType(), True),\n",
    "        StructField(\"object\", StringType(), True),\n",
    "        StructField(\"value\", StringType(), True)])\n",
    "    \n",
    "    # Create DF\n",
    "    complete_fpath = fpath + tsv_name + '.tsv'\n",
    "    df = spark.read.csv(complete_fpath, header = 'true', schema = schema, sep = '\\t')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load the data from 'yagoFacts.tsv' into a DataFrame called 'df'\n",
    "df = load_tsv('yagoFacts')\n",
    "\n",
    "# Load the data from 'yagoTransitiveType.tsv' into a DataFrame called 'df_subclasses'\n",
    "df_subclasses = load_tsv('yagoTransitiveType')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3 Understand the database schema\n",
    "\n",
    "Let's look at the schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+--------------------+-----+\n",
      "|                  id|             subject|   predicate|              object|value|\n",
      "+--------------------+--------------------+------------+--------------------+-----+\n",
      "|<id_rB6isMnplh_H?...|<Jesús_Rivera_Sán...|<isLeaderOf>|<Pueblo_of_Naranj...| null|\n",
      "|<id_BOK!FvTDPu_H?...|      <Elizabeth_II>|<isLeaderOf>|<Royal_Numismatic...| null|\n",
      "|<id_Uy5EwU3nX1_H?...|  <Richard_Stallman>|<isLeaderOf>|<Free_Software_Fo...| null|\n",
      "|<id_A?rIHtKpyX_H?...|    <Keith_Peterson>|<isLeaderOf>|     <Cambridge_Bay>| null|\n",
      "|<id_vzhzgmCR5Y_H?...|<William_H._Sewar...|<isLeaderOf>|<9th_New_York_Hea...| null|\n",
      "|<id_GqUh9jFAN?_H?...|          <Andranik>|<isLeaderOf>|   <Armenian_fedayi>| null|\n",
      "|<id_s60Psk1DHb_H?...|<Ramasamy_Palanis...|<isLeaderOf>|<Democratic_Actio...| null|\n",
      "|<id_pII60Mnz8o_H?...|        <Matt_Bevin>|<isLeaderOf>|<Kentucky_Air_Nat...| null|\n",
      "|<id_losV58WRWE_H?...|       <Leonard_Leo>|<isLeaderOf>|<Federalist_Society>| null|\n",
      "|<id_b2c!d9tP5s_H?...|<James_Vincent_Cl...|<isLeaderOf>|<Bennington,_New_...| null|\n",
      "|<id_SuFKiU!7li_H?...|      <Amjad_Bashir>|<isLeaderOf>|  <Khushab_District>| null|\n",
      "|<id_OX7FOTxk6P_H?...|<Tushar_Amarsinh_...|<isLeaderOf>|     <Mota,_Gujarat>| null|\n",
      "|<id_xHENPT1B2!_H?...|  <Yiannis_Boutaris>|<isLeaderOf>|      <Thessaloniki>| null|\n",
      "|<id_NmF7gAStes_H?...|<Margaret_Chew_Ba...|<isLeaderOf>|  <American_INSIGHT>| null|\n",
      "|<id_TNRSN0E1Z8_H?...|     <Oscar_Braynon>|<isLeaderOf>|        <Allapattah>| null|\n",
      "|<id_Fx6ys5YRe3_H?...|<Margrethe_II_of_...|<isLeaderOf>|         <Greenland>| null|\n",
      "|<id_WDh6qsx6dr_H?...|<Fernando_Álvarez...|<isLeaderOf>|  <Army_of_Flanders>| null|\n",
      "|<id_HMzvj0NINA_H?...|          <Om_Birla>|<isLeaderOf>|   <Kota,_Rajasthan>| null|\n",
      "|<id_jbwYxBY!bD_H?...| <Shamsuzzaman_Khan>|<isLeaderOf>|    <Bangla_Academy>| null|\n",
      "|<id_EzbN7xBPSg_H?...|     <Perry_Trimper>|<isLeaderOf>|  <North_West_River>| null|\n",
      "+--------------------+--------------------+------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+--------------------+---------+--------------------+-----+\n",
      "|                  id|             subject|predicate|              object|value|\n",
      "+--------------------+--------------------+---------+--------------------+-----+\n",
      "|<id_IDwmgVA9s0_KC...|<1908_St._Louis_B...| rdf:type|<wikicat_Baltimor...| null|\n",
      "|<id_IDwmgVA9s0_KC...|<1908_St._Louis_B...| rdf:type|<wikicat_Major_Le...| null|\n",
      "|<id_IDwmgVA9s0_KC...|<1908_St._Louis_B...| rdf:type|<wikicat_St._Loui...| null|\n",
      "|<id_IDwmgVA9s0_KC...|<1908_St._Louis_B...| rdf:type|<wordnet_abstract...| null|\n",
      "|<id_IDwmgVA9s0_KC...|<1908_St._Louis_B...| rdf:type|<wordnet_fundamen...| null|\n",
      "|<id_IDwmgVA9s0_KC...|<1908_St._Louis_B...| rdf:type|<wordnet_measure_...| null|\n",
      "|<id_IDwmgVA9s0_KC...|<1908_St._Louis_B...| rdf:type|<wordnet_season_1...| null|\n",
      "|<id_IDwmgVA9s0_KC...|<1908_St._Louis_B...| rdf:type|<wordnet_time_per...| null|\n",
      "|<id_IDwmgVA9s0_KC...|<1908_St._Louis_B...| rdf:type|           owl:Thing| null|\n",
      "|<id_mUhCPivGvE_KC...|        <A1086_road>| rdf:type|     <wikicat_Roads>| null|\n",
      "|<id_mUhCPivGvE_KC...|        <A1086_road>| rdf:type|<wikicat_Roads_in...| null|\n",
      "|<id_mUhCPivGvE_KC...|        <A1086_road>| rdf:type|<wikicat_Roads_in...| null|\n",
      "|<id_mUhCPivGvE_KC...|        <A1086_road>| rdf:type|<wikicat_Roads_in...| null|\n",
      "|<id_mUhCPivGvE_KC...|        <A1086_road>| rdf:type|<wordnet_artifact...| null|\n",
      "|<id_mUhCPivGvE_KC...|        <A1086_road>| rdf:type|<wordnet_object_1...| null|\n",
      "|<id_mUhCPivGvE_KC...|        <A1086_road>| rdf:type|<wordnet_physical...| null|\n",
      "|<id_mUhCPivGvE_KC...|        <A1086_road>| rdf:type|<wordnet_road_104...| null|\n",
      "|<id_mUhCPivGvE_KC...|        <A1086_road>| rdf:type|<wordnet_way_1045...| null|\n",
      "|<id_mUhCPivGvE_KC...|        <A1086_road>| rdf:type|<wordnet_whole_10...| null|\n",
      "|<id_mUhCPivGvE_KC...|        <A1086_road>| rdf:type|     <yagoGeoEntity>| null|\n",
      "+--------------------+--------------------+---------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Have a look at the beginning of both files\n",
    "df.show(20)\n",
    "df_subclasses.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The useful information is in columns \"subject\", \"predicate\" and \"object\". \"predicate\" defines the relation between entities \"subject\" and \"object\". For example, for \"Albert Einstein was born in Ulm\", \"Albert Einstein\" is the subject, \"was born in\" is the predicate and \"Ulm\" is the object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.4 Simple query example\n",
    "\n",
    "To get information about where Albert Einstein was born, we load data into Spark using the following query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+---------------------------------------------+-----------+---------------+-----+\n",
      "|id                            |subject                                      |predicate  |object         |value|\n",
      "+------------------------------+---------------------------------------------+-----------+---------------+-----+\n",
      "|<id_thPX9b1zg!_7fp_kCyegRoKet>|<William_Jones_(Welsh_footballer,_born_1876)>|<wasBornIn>|<Penrhiwceiber>|null |\n",
      "+------------------------------+---------------------------------------------+-----------+---------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "born_city_df = df.where(\"predicate == '<wasBornIn>'\")\n",
    "born_city_df.show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+-----------------+-----------+------+-----+\n",
      "|id                            |subject          |predicate  |object|value|\n",
      "+------------------------------+-----------------+-----------+------+-----+\n",
      "|<id_sbCVliqDT2_7fp_SjB1FOwfPE>|<Albert_Einstein>|<wasBornIn>|<Ulm> |null |\n",
      "+------------------------------+-----------------+-----------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "born_city_df.where(\"subject = '<Albert_Einstein>'\").show(born_city_df.count(), False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may wonder how one would know whether to use the predicate '&lt;wasBornIn&gt;' or '&lt;was_born_in&gt;' and subject '&lt;Albert_Einstein&gt;' or '&lt;AlbertEinstein&gt;'. For YAGO subjects (and objects), the naming is aligned with Wikipedia. For example, Albert Einstein's wiki is: https://en.wikipedia.org/wiki/Albert_Einstein and you can see it is 'Albert_Einstein'. \n",
    "\n",
    "For predicates, you can look at the \"property\" list from the [yago web interface](https://gate.d5.mpi-inf.mpg.de/webyagospotlx/WebInterface?L01=%3Fx&L0R=%3CwasBornIn%3E&L02=%3Fc&L0T=&L03=&L0L=&L04=&L05=&L11=&L1R=&L12=&L1T=&L13=&L1L=&L14=&L15=&L21=&L2R=&L22=&L2T=&L23=&L2L=&L24=&L25=&L31=&L3R=&L32=&L3T=&L33=&L3L=&L34=&L35=&L41=&L4R=&L42=&L4T=&L43=&L4L=&L44=&L45=). \n",
    "Try different queries with this web interface query to understand more how to query YAGO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.5 Simple motif example (Question A)\n",
    "\n",
    "In this part of the homework, you are required to use **motif** to find out answer to the 4 questions. Please complete the following example to find out: \"Which city was Albert Einstein born in?\" using motif queries instead of  SQL queries on the first dataframe (`df`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph: \n",
      "GraphFrame(v:[id: string, subject: string], e:[src: string, dst: string])\n",
      " \n",
      "Vertices: \n",
      "+---------------------------+------------------------------+\n",
      "|subject                    |id                            |\n",
      "+---------------------------+------------------------------+\n",
      "|<nl/Kars_van_Tarel>        |<id_ygSgtwYWIJ_7fp_lGhmJyFgmN>|\n",
      "|<James_J._Couzens>         |<id_DCT32lh0dA_7fp_RpE0TDEnyY>|\n",
      "|<Albert_Russell_(director)>|<id_IjUg1kUfud_7fp_enl8MQVrnA>|\n",
      "|<Paddy_O'Connor>           |<id_dy1deLP3XL_7fp_Q?oM5KbAHV>|\n",
      "|<Jackie_Stedall>           |<id_Oz2rAe9QE4_7fp_0mZZ28tJjV>|\n",
      "+---------------------------+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Edges: \n",
      "+---------------------------------------------+---------------+\n",
      "|src                                          |dst            |\n",
      "+---------------------------------------------+---------------+\n",
      "|<William_Jones_(Welsh_footballer,_born_1876)>|<Penrhiwceiber>|\n",
      "|<Prince_Konrad_of_Hohenlohe-Schillingsfürst> |<Vienna>       |\n",
      "|<Sean_Faircloth>                             |<Bangor,_Maine>|\n",
      "|<Beatrice_Welles>                            |<Manhattan>    |\n",
      "|<Paul_Sturzenegger>                          |<Argentina>    |\n",
      "+---------------------------------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NOTE: I use born_city_df because it is already filtered to predicate = \"<WasBornIn>\"\n",
    "\n",
    "# Define vertices and edges\n",
    "v = born_city_df.select(\"subject\", \"id\").distinct()\n",
    "e = born_city_df.withColumnRenamed(\"subject\", \"src\").withColumnRenamed(\"object\", \"dst\").select(\"src\", \"dst\")\n",
    "\n",
    "# Build the graph\n",
    "g = GraphFrame(v, e)\n",
    "print(\"Graph: \"); print(g); print(\" \")\n",
    "print(\"Vertices: \"); g.vertices.show(5, False)\n",
    "print(\"Edges: \"); g.edges.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|e                         |\n",
      "+--------------------------+\n",
      "|[<Albert_Einstein>, <Ulm>]|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Write a motif query and filter on Albert Einstein to see where he was born\n",
    "motifs = g.find(\"()-[e]->()\").filter(\"e.src = '<Albert_Einstein>'\").show(1, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.6 Some useful tips\n",
    "\n",
    "### Get a subset of YAGO database\n",
    "YAGO database is large, so we don't try to load the entire database into a dataframe and then query it. If you do this, you will find that you won't even be able to execute `df.take(1)`, as it would take up too much of space (at least on a laptop). Instead, you use Spark SQL commands or `df.where` to get a suitable fraction of the data.\n",
    "\n",
    "### Try the queries in the YAGO web interface first\n",
    "It is sometimes tricky to get the right \"subject\", \"predicate\" and \"object\". It is easier if you start from [yago web interface](https://gate.d5.mpi-inf.mpg.de/webyagospotlx/WebInterface?L01=%3Fx&L0R=%3CwasBornIn%3E&L02=%3Fc&L0T=&L03=&L0L=&L04=&L05=&L11=&L1R=&L12=&L1T=&L13=&L1L=&L14=&L15=&L21=&L2R=&L22=&L2T=&L23=&L2L=&L24=&L25=&L31=&L3R=&L32=&L3T=&L33=&L3L=&L34=&L35=&L41=&L4R=&L42=&L4T=&L43=&L4L=&L44=&L45=) rather than directly querying in Pyspark. Once your query works, you can convert your query to Pyspark code. Note that sometimes the web version of object/subject code may be different from what you need to type here. For example, company code is &lt;wordnet_company_108058098&gt; when you do the query here but when you do it via the web interface it is &lt;wordnet company 108058098&gt;. \n",
    "\n",
    "### Be patient and don't do this exercise in the last minute\n",
    "Some trial and error is needed to get the query right and it may take some time get the result for a query. For these reasons, we advise you not to wait to work out this exercise just before the submission deadline. \n",
    "\n",
    "### Make sure to get the initialization actions right\n",
    "For this exercise, you will be using GraphFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Politicians who are also scientists (Question B)\n",
    "Find all politicians who are also scientists. Output top 20 of them. How many people are in the dataset who are both scientists and politicians?\n",
    "Please follow these steps:\n",
    "* Operate on the subsets of `df_subclasses` where the objects are `'<wordnet_scientist_110560637>` (scientists) and `'<wordnet_politician_110450303>'` (politicians), and where the predicates are `rdf:type`.\n",
    "* Use graphframes and the right parts of `df_subclasses` to construct a graph whose (directed) edges point from subjects to objects. Hence, its source vertices are subjects and it destination vertices are objects. It may be convenient to use intermediate DataFrames and join all the required dataframes of edges and vertices.\n",
    "* The subjects will be people and the objects will be classes (e.g., scientists, politicians).\n",
    "* Use a motif query to find all instances that fulfil the criteria specified in the question.\n",
    "* It is a good idea to define a function that takes a DataFrame and outputs a set of data frames for vertices and edges.\n",
    "\n",
    "Please sort the output alphabetically by the person column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------+--------------------+-----+\n",
      "|                  id|             subject|predicate|              object|value|\n",
      "+--------------------+--------------------+---------+--------------------+-----+\n",
      "|<id_wGHfubCwBs_KC...|<Jean-Baptiste-Jo...| rdf:type|<wordnet_politici...| null|\n",
      "|<id_EQgbQobwPR_KC...|       <Reg_Freeson>| rdf:type|<wordnet_politici...| null|\n",
      "|<id_AZU1dcMWPB_KC...|       <Akbar_Ahmad>| rdf:type|<wordnet_politici...| null|\n",
      "|<id_OqLYLwYtOx_KC...|<it/Luigi_Di_Paol...| rdf:type|<wordnet_politici...| null|\n",
      "|<id_X76ScLZ?xM_KC...|         <Larry_Wos>| rdf:type|<wordnet_scientis...| null|\n",
      "+--------------------+--------------------+---------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a subset of df_subclasses including only scientists and politicians\n",
    "poli_sci_df = df_subclasses.where(\"object == '<wordnet_scientist_110560637>' or object == '<wordnet_politician_110450303>'\")\n",
    "\n",
    "# Additionally, filter on predicate = rdf:type\n",
    "poli_sci_df = poli_sci_df.where(\"predicate = 'rdf:type'\")\n",
    "\n",
    "# Display the first 20 rows to make sure this worked\n",
    "poli_sci_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Vertices: \n",
      "+-----------------------+------------------------------+\n",
      "|subject                |id                            |\n",
      "+-----------------------+------------------------------+\n",
      "|<A._Richard_Newton>    |<id_d1dFPQY3qb_KCM_shP4LW!R1g>|\n",
      "|<Abby_Lee_(politician)>|<id_RqACHpnJtB_KCM_aXuIGKiXUR>|\n",
      "|<Abd_al-Karim_al-Jundi>|<id_aDyZSu5v5f_KCM_aXuIGKiXUR>|\n",
      "|<Abd_al-Majid_al-Rafei>|<id_Z9leXdc3mN_KCM_aXuIGKiXUR>|\n",
      "|<Abdul_Ali_Mazari>     |<id_0zWAROacTh_KCM_aXuIGKiXUR>|\n",
      "+-----------------------+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Destination Vertices: \n",
      "+------------------------------+----------+\n",
      "|id                            |subject   |\n",
      "+------------------------------+----------+\n",
      "|<wordnet_politician_110450303>|politician|\n",
      "|<wordnet_scientist_110560637> |scientist |\n",
      "+------------------------------+----------+\n",
      "\n",
      "Graph: \n",
      "GraphFrame(v:[id: string, subject: string], e:[src: string, dst: string])\n",
      " \n",
      "Vertices: \n",
      "+------------------------------+------------------------------+\n",
      "|id                            |subject                       |\n",
      "+------------------------------+------------------------------+\n",
      "|<wordnet_politician_110450303>|politician                    |\n",
      "|<wordnet_scientist_110560637> |scientist                     |\n",
      "|<A._Richard_Newton>           |<id_d1dFPQY3qb_KCM_shP4LW!R1g>|\n",
      "|<Abby_Lee_(politician)>       |<id_RqACHpnJtB_KCM_aXuIGKiXUR>|\n",
      "|<Abd_al-Karim_al-Jundi>       |<id_aDyZSu5v5f_KCM_aXuIGKiXUR>|\n",
      "+------------------------------+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Edges: \n",
      "+----------------------------+------------------------------+\n",
      "|src                         |dst                           |\n",
      "+----------------------------+------------------------------+\n",
      "|<Jean-Baptiste-Joseph_Gobel>|<wordnet_politician_110450303>|\n",
      "|<Reg_Freeson>               |<wordnet_politician_110450303>|\n",
      "|<Akbar_Ahmad>               |<wordnet_politician_110450303>|\n",
      "|<it/Luigi_Di_Paolantonio>   |<wordnet_politician_110450303>|\n",
      "|<Larry_Wos>                 |<wordnet_scientist_110560637> |\n",
      "+----------------------------+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define source vertices (subjects)\n",
    "# NOTE: I need to use dropDuplicates() because for some reason every name shows up \n",
    "# two times with two separate IDs and I do not want to do any double counting\n",
    "source_v = poli_sci_df.select(\"subject\",\"id\").dropDuplicates([\"subject\"])\n",
    "print(\"Source Vertices: \"); source_v.show(5, False)\n",
    "\n",
    "# Define destination vertices (objects)\n",
    "destination_v = sqlContext.createDataFrame([(\"<wordnet_politician_110450303>\",\"politician\"),\n",
    "                                            (\"<wordnet_scientist_110560637>\",\"scientist\")], [\"id\", \"subject\"])\n",
    "print(\"Destination Vertices: \"); destination_v.show(2, False)\n",
    "\n",
    "# Combine source vertices and destination vertices\n",
    "v = destination_v.unionAll(source_v)\n",
    "\n",
    "# Define edges\n",
    "e = poli_sci_df.withColumnRenamed(\"subject\",\"src\").withColumnRenamed(\"object\",\"dst\").select(\"src\",\"dst\")\n",
    "\n",
    "g = GraphFrame(v, e)\n",
    "print(\"Graph: \"); print(g); print(\" \")\n",
    "print(\"Vertices: \"); g.vertices.show(5, False)\n",
    "print(\"Edges: \"); g.edges.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of politicians that are also scientists is: 7182\n"
     ]
    }
   ],
   "source": [
    "# Motif query\n",
    "motifs = g.find(\"(a)-[e]->(b); (a)-[e2]->(c)\")\n",
    "\n",
    "# Filter to include only politicians\n",
    "poli_motifs = motifs.filter(\"b.id == '<wordnet_politician_110450303>'\")\n",
    "\n",
    "# Filter and count the number of politicians who are also scientists\n",
    "poli_sci_motifs = poli_motifs.filter(\"c.id == '<wordnet_scientist_110560637>'\")\n",
    "print(\"The total number of politicians that are also scientists is:\", poli_sci_motifs.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|src                      |\n",
      "+-------------------------+\n",
      "|<A._C._Cuza>             |\n",
      "|<A._P._J._Abdul_Kalam>   |\n",
      "|<Aad_Kosto>              |\n",
      "|<Aad_Nuis>               |\n",
      "|<Aaron_Aaronsohn>        |\n",
      "|<Aaron_Farrugia>         |\n",
      "|<Ab_Klink>               |\n",
      "|<Abba_P._Lerner>         |\n",
      "|<Abbas_Ahmad_Akhoundi>   |\n",
      "|<Abbie_Hoffman>          |\n",
      "|<Abbott_Lawrence_Lowell> |\n",
      "|<Abdallah_Salem_el-Badri>|\n",
      "|<Abdelbaki_Hermassi>     |\n",
      "|<Abdellatif_Abid>        |\n",
      "|<Abdelouahed_Souhail>    |\n",
      "|<Abdelwahed_Radi>        |\n",
      "|<Abdesslam_Yassine>      |\n",
      "|<Abdi_Farah_Shirdon>     |\n",
      "|<Abdirahman_Duale_Beyle> |\n",
      "|<Abdiweli_Mohamed_Ali>   |\n",
      "+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the top 20 politicians who are also scientists\n",
    "poli_sci_motifs.select(\"e.src\").orderBy('e.src', ascending=True).show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Companies whose founders were born in London (Question C)\n",
    "For companies, use `'<wordnet_company_108058098>'`. \n",
    "For *\"being founder\"*, use `<created>`.\n",
    "\n",
    "By now, you will understand which DataFrame to use for what. \n",
    "\n",
    "Set up a graph and use a motif query to find companies whose founders were born in London.\n",
    "Please take some time to figure out how a suitable configuration of nodes and edges should look like.  How many such companies are there in our dataset?\n",
    "\n",
    "Please sort the output alphabetically by the founder column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------+--------------------+-----+\n",
      "|                  id|             subject|predicate|              object|value|\n",
      "+--------------------+--------------------+---------+--------------------+-----+\n",
      "|<id_mH08dclRGm_KC...|<Ice_Cream_Man_(b...| rdf:type|<wordnet_company_...| null|\n",
      "|<id_sPDFWJYYVp_KC...|<Bangladesh_Insti...| rdf:type|<wordnet_company_...| null|\n",
      "|<id_9P3ZvWWaBA_KC...|         <Giacomini>| rdf:type|<wordnet_company_...| null|\n",
      "|<id_VER4Spac3k_KC...|     <Nfrastructure>| rdf:type|<wordnet_company_...| null|\n",
      "|<id_xnF4xFL9GN_KC...|<nl/Orania_(aarda...| rdf:type|<wordnet_company_...| null|\n",
      "+--------------------+--------------------+---------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+------------------+---------+--------------------+-----+\n",
      "|                  id|           subject|predicate|              object|value|\n",
      "+--------------------+------------------+---------+--------------------+-----+\n",
      "|<id_Y2g!qC1Yob_Mx...|  <Donald_Moffitt>|<created>|<Second_Genesis_(...| null|\n",
      "|<id_OQrETXPUbw_Mx...|<Ludwig_Bemelmans>|<created>| <Madeline's_Rescue>| null|\n",
      "|<id_Ev18N8t0R0_Mx...|<Hitomi_Shimatani>|<created>|    <Perseus_(song)>| null|\n",
      "|<id_jV7cchsU9C_Mx...|     <Steven_Paul>|<created>|    <The_Karate_Dog>| null|\n",
      "|<id_4xemGzhGuu_Mx...|      <Glu_Mobile>|<created>|<Bush_vs._Kerry_B...| null|\n",
      "+--------------------+------------------+---------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+--------------------+-----------+---------------+-----+\n",
      "|                  id|             subject|  predicate|         object|value|\n",
      "+--------------------+--------------------+-----------+---------------+-----+\n",
      "|<id_thPX9b1zg!_7f...|<William_Jones_(W...|<wasBornIn>|<Penrhiwceiber>| null|\n",
      "|<id_jj0mycL2ED_7f...|<Prince_Konrad_of...|<wasBornIn>|       <Vienna>| null|\n",
      "|<id_KPjIE3dH6?_7f...|    <Sean_Faircloth>|<wasBornIn>|<Bangor,_Maine>| null|\n",
      "|<id_jqUTrV8GuG_7f...|   <Beatrice_Welles>|<wasBornIn>|    <Manhattan>| null|\n",
      "|<id_etcRAp!dE4_7f...| <Paul_Sturzenegger>|<wasBornIn>|    <Argentina>| null|\n",
      "+--------------------+--------------------+-----------+---------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a subset of df_subclasses including only companies\n",
    "company_df = df_subclasses.where(\"object == '<wordnet_company_108058098>'\")\n",
    "\n",
    "# Create a subset of df including only creators\n",
    "creator_df = df.where(\"predicate == '<created>'\")\n",
    "\n",
    "# Display the first 5 rows to make sure this worked; also display born_city_df because we will use it here\n",
    "company_df.show(5)\n",
    "creator_df.show(5)\n",
    "born_city_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Vertices: \n",
      "+----------------------------+------------------------+\n",
      "|id                          |object                  |\n",
      "+----------------------------+------------------------+\n",
      "|<2nd_Jebtsundamba_Khutughtu>|<Altanbulag,_Töv>       |\n",
      "|<A.G._Visser>               |<Fraserburg>            |\n",
      "|<A._J._Gass>                |<Bellflower,_California>|\n",
      "|<A._J._Pollock>             |<Hebron,_Connecticut>   |\n",
      "|<A._K._Sarwate>             |<Amravati>              |\n",
      "+----------------------------+------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Destination Vertices: \n",
      "+------------------------------+---------------------------+\n",
      "|id                            |object                     |\n",
      "+------------------------------+---------------------------+\n",
      "|<de/Hanomag_Lohnhärterei>     |<wordnet_company_108058098>|\n",
      "|<de/Superfilm>                |<wordnet_company_108058098>|\n",
      "|<S-Bank>                      |<wordnet_company_108058098>|\n",
      "|<RAP4>                        |<wordnet_company_108058098>|\n",
      "|<de/Brauerei_Ritter_St._Georg>|<wordnet_company_108058098>|\n",
      "+------------------------------+---------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define source vertices (founders)\n",
    "source_v = born_city_df.select(\"subject\",\"object\").withColumnRenamed(\"subject\",\"id\").dropDuplicates([\"id\"])\n",
    "print(\"Source Vertices: \"); source_v.show(5, False)\n",
    "\n",
    "# Define destination vertices (objects)\n",
    "destination_v = company_df.select(\"subject\",\"object\").withColumnRenamed(\"subject\",\"id\").distinct()\n",
    "print(\"Destination Vertices: \"); destination_v.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph: \n",
      "GraphFrame(v:[id: string, object: string], e:[src: string, dst: string])\n",
      " \n",
      "Vertices: \n",
      "+------------------------------+---------------------------+\n",
      "|id                            |object                     |\n",
      "+------------------------------+---------------------------+\n",
      "|<de/Brauerei_Ritter_St._Georg>|<wordnet_company_108058098>|\n",
      "|<WestNet_Wireless>            |<wordnet_company_108058098>|\n",
      "|<New_Ocean_Media>             |<wordnet_company_108058098>|\n",
      "|<Austen_Morris_Associates>    |<wordnet_company_108058098>|\n",
      "|<de/Bermuda_Buggy>            |<wordnet_company_108058098>|\n",
      "+------------------------------+---------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Edges: \n",
      "+------------------+------------------------+\n",
      "|src               |dst                     |\n",
      "+------------------+------------------------+\n",
      "|<Donald_Moffitt>  |<Second_Genesis_(novel)>|\n",
      "|<Ludwig_Bemelmans>|<Madeline's_Rescue>     |\n",
      "|<Hitomi_Shimatani>|<Perseus_(song)>        |\n",
      "|<Steven_Paul>     |<The_Karate_Dog>        |\n",
      "|<Glu_Mobile>      |<Bush_vs._Kerry_Boxing> |\n",
      "+------------------+------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combine source vertices and destination vertices\n",
    "v = destination_v.unionAll(source_v)\n",
    "\n",
    "# Define edges\n",
    "e = creator_df.withColumnRenamed(\"subject\",\"src\").withColumnRenamed(\"object\",\"dst\").select(\"src\",\"dst\")\n",
    "\n",
    "# Create the graph\n",
    "g = GraphFrame(v, e)\n",
    "print(\"Graph: \"); print(g); print(\" \")\n",
    "print(\"Vertices: \"); g.vertices.show(5, False)\n",
    "print(\"Edges: \"); g.edges.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                   a|                   e|                   b|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|[<Mona_Yamamoto>,...|[<Mona_Yamamoto>,...|[<Asahi_Broadcast...|\n",
      "|[<Sufjan_Stevens>...|[<Sufjan_Stevens>...|[<Asthmatic_Kitty...|\n",
      "|[<Charlie_Robinso...|[<Charlie_Robinso...|[<C._H._Robinson>...|\n",
      "|[<Milt_Gabler>, <...|[<Milt_Gabler>, <...|[<Commodore_Recor...|\n",
      "|[<Daniel_Cane>, <...|[<Daniel_Cane>, <...|[<CourseInfo>, <w...|\n",
      "|[<DirecTV>, <word...|[<DirecTV>, <Dire...|[<DirecTV_Now>, <...|\n",
      "|[<AT&T>, <wordnet...|[<AT&T>, <DirecTV...|[<DirecTV_Now>, <...|\n",
      "|[<Fifth_Generatio...|[<Fifth_Generatio...|[<FastBack>, <wor...|\n",
      "|[<Rockwilder>, <Q...|[<Rockwilder>, <F...|[<Fuel_Records>, ...|\n",
      "|[<Witness_Lee>, <...|[<Witness_Lee>, <...|[<Living_Stream_M...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Motif query\n",
    "# NOTE: apply a filter to eliminate the rare instances where two people are connected by an edge\n",
    "motifs = g.find(\"(a)-[e]->(b)\").filter(\"b.object = '<wordnet_company_108058098>'\")\n",
    "motifs.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of company founders who were born in London is: 53\n",
      "The number of companies whose founders were born in London is: 59\n"
     ]
    }
   ],
   "source": [
    "# Filter to include only founders who were born in London\n",
    "london_motifs = motifs.filter(\"a.object == '<London>'\")\n",
    "\n",
    "# Count how many company founders were born in London\n",
    "founder_count = london_motifs.select(\"e.src\").distinct().count()\n",
    "print(\"The number of company founders who were born in London is:\", founder_count)\n",
    "\n",
    "# Count how many companies had founders who were born in London\n",
    "companies_count = london_motifs.select(\"e.dst\").distinct().count()\n",
    "print(\"The number of companies whose founders were born in London is:\", companies_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+-------------------------------------+\n",
      "|src                            |dst                                  |\n",
      "+-------------------------------+-------------------------------------+\n",
      "|<Adam_Hamdy>                   |<Dare_Comics>                        |\n",
      "|<Alexander_Asseily>            |<Jawbone_(company)>                  |\n",
      "|<Antony_Jay>                   |<Video_Arts>                         |\n",
      "|<Aubrey_de_Grey>               |<SENS_Research_Foundation>           |\n",
      "|<Ben_Horowitz>                 |<Andreessen_Horowitz>                |\n",
      "|<Bernard_MacMahon_(filmmaker)> |<LO-MAX_Records>                     |\n",
      "|<Brian_Maxwell>                |<PowerBar>                           |\n",
      "|<Bruno_Heller>                 |<Primrose_Hill_Productions>          |\n",
      "|<Charlie_Chaplin>              |<United_Artists>                     |\n",
      "|<Dan_Joyce>                    |<Kurrupt_Recordings_HARD>            |\n",
      "|<Daniel_James_(game_developer)>|<Three_Rings_Design>                 |\n",
      "|<David_Harel>                  |<I-Logix>                            |\n",
      "|<David_Heyman>                 |<Heyday_Films>                       |\n",
      "|<David_Kimche>                 |<Israel_Council_on_Foreign_Relations>|\n",
      "|<Demis_Hassabis>               |<DeepMind>                           |\n",
      "|<Ellen_Browning_Scripps>       |<Scripps_Health>                     |\n",
      "|<Ellen_Browning_Scripps>       |<Luce,_Forward,_Hamilton_&_Scripps>  |\n",
      "|<Elliot_James>                 |<Blossöm_Records>                    |\n",
      "|<Emma_Thomas>                  |<Syncopy_Inc.>                       |\n",
      "|<Ernest_Webb>                  |<Rezolution_Pictures>                |\n",
      "+-------------------------------+-------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display a list of the company founders who were born in London\n",
    "# NOTE: Some names show up more than once because the person founded multiple companies (i.e. Ellen Browning Scripps)\n",
    "london_motifs.select(\"e.src\",\"e.dst\").orderBy('e.src', ascending=True).show(20,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Writers who have won a Nobel Prize in any discipline, including economics (Question D)\n",
    "Tags for nobel prizes look like these: `'<Nobel_Prize_in_Chemistry>`, `<Nobel_Prize_in_Physics>'`, `<Nobel_Prize>` or `<Nobel_Prize>` etc.\n",
    "We are also counting this one: `'<Nobel_Memorial_Prize_in_Economic_Sciences>'`.\n",
    "\n",
    "The tag for writers is `'<wordnet_writer_110794014>'`.\n",
    "\n",
    "You will need to use `'<hasWonPrize>'` as a predicate.\n",
    "\n",
    "Please sort the output alphabetically by the person column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------+--------------------+-----+\n",
      "|                  id|             subject|predicate|              object|value|\n",
      "+--------------------+--------------------+---------+--------------------+-----+\n",
      "|<id_Rjw3Ie7SP9_KC...|    <Jessica_Yellin>| rdf:type|<wordnet_writer_1...| null|\n",
      "|<id_FmLL6QBeue_KC...|<es/Bernardo_Marí...| rdf:type|<wordnet_writer_1...| null|\n",
      "|<id_2p3oRVZ3Xj_KC...|    <Phyllis_Tickle>| rdf:type|<wordnet_writer_1...| null|\n",
      "|<id_rn12Pb4Pmh_KC...|    <Roger_McDonald>| rdf:type|<wordnet_writer_1...| null|\n",
      "|<id_pEyVYsG0Oi_KC...|   <es/Tomás_Lander>| rdf:type|<wordnet_writer_1...| null|\n",
      "+--------------------+--------------------+---------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+--------------------+-------------+--------------------+-----+\n",
      "|                  id|             subject|    predicate|              object|value|\n",
      "+--------------------+--------------------+-------------+--------------------+-----+\n",
      "|<id_Fp0LhlXTCr_Yf...|  <Baruj_Benacerraf>|<hasWonPrize>|<Nobel_Prize_in_P...| null|\n",
      "|<id_s252JUOzj2_Yf...|<Oliver_E._Willia...|<hasWonPrize>|<Nobel_Memorial_P...| null|\n",
      "|<id_Dk!0PCE!6f_Yf...|        <Ilya_Frank>|<hasWonPrize>|<Nobel_Prize_in_P...| null|\n",
      "|<id_mt5ZorALcK_Yf...|       <Martin_Ryle>|<hasWonPrize>|<Nobel_Prize_in_P...| null|\n",
      "|<id_2zyoqbFz2K_Yf...| <Hamilton_O._Smith>|<hasWonPrize>|<Nobel_Prize_in_P...| null|\n",
      "+--------------------+--------------------+-------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a subset of df_subclasses including only writers\n",
    "writers_df = df_subclasses.where(\"object == '<wordnet_writer_110794014>'\")\n",
    "\n",
    "# Create a subset of df including only individuals who have won prizes\n",
    "prize_winners_df = df.where(\"predicate == '<hasWonPrize>'\")\n",
    "\n",
    "# Filter prize_winners_df to include only Nobel prizes\n",
    "prize_winners_df = prize_winners_df.where(\"object == '<Nobel_Prize>' or \\\n",
    "object == '<Nobel_Peace_Prize>' or object == '<Nobel_Prize_in_Physics>' or \\\n",
    "object == '<Nobel_Prize_in_Literature>' or object == '<Nobel_Prize_in_Chemistry>' or \\\n",
    "object == '<Nobel_Prize_in_Physiology_or_Medicine>' or object == '<Nobel_Memorial_Prize_in_Economic_Sciences>'\")\n",
    "\n",
    "# Display the first 5 rows to make sure this worked\n",
    "writers_df.show(5)\n",
    "prize_winners_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Vertices: \n",
      "+----------------------------+---------------------------------------+\n",
      "|id                          |object                                 |\n",
      "+----------------------------+---------------------------------------+\n",
      "|<Carl_von_Ossietzky>        |<Nobel_Peace_Prize>                    |\n",
      "|<Grazia_Deledda>            |<Nobel_Prize_in_Literature>            |\n",
      "|<Pierre_Curie>              |<Nobel_Prize_in_Physics>               |\n",
      "|<Richard_R._Schrock>        |<Nobel_Prize_in_Chemistry>             |\n",
      "|<Stanley_Cohen_(biochemist)>|<Nobel_Prize_in_Physiology_or_Medicine>|\n",
      "+----------------------------+---------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Destination Vertices: \n",
      "+--------------------------+------+\n",
      "|id                        |object|\n",
      "+--------------------------+------+\n",
      "|<wordnet_writer_110794014>|writer|\n",
      "+--------------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define source vertices (name, prize)\n",
    "source_v = prize_winners_df.select(\"subject\",\"object\").withColumnRenamed(\"subject\",\"id\").dropDuplicates([\"id\"])\n",
    "print(\"Source Vertices: \"); source_v.show(5, False)\n",
    "\n",
    "# Define destination vertices (writer_id)\n",
    "destination_v = sqlContext.createDataFrame([(\"<wordnet_writer_110794014>\",\"writer\")], [\"id\", \"object\"])\n",
    "print(\"Destination Vertices: \"); destination_v.show(1, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph: \n",
      "GraphFrame(v:[id: string, object: string], e:[src: string, dst: string])\n",
      " \n",
      "Vertices: \n",
      "+--------------------------+---------------------------+\n",
      "|id                        |object                     |\n",
      "+--------------------------+---------------------------+\n",
      "|<wordnet_writer_110794014>|writer                     |\n",
      "|<Carl_von_Ossietzky>      |<Nobel_Peace_Prize>        |\n",
      "|<Grazia_Deledda>          |<Nobel_Prize_in_Literature>|\n",
      "|<Pierre_Curie>            |<Nobel_Prize_in_Physics>   |\n",
      "|<Richard_R._Schrock>      |<Nobel_Prize_in_Chemistry> |\n",
      "+--------------------------+---------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Edges: \n",
      "+---------------------------------+--------------------------+\n",
      "|src                              |dst                       |\n",
      "+---------------------------------+--------------------------+\n",
      "|<Jessica_Yellin>                 |<wordnet_writer_110794014>|\n",
      "|<es/Bernardo_María_de_la_Calzada>|<wordnet_writer_110794014>|\n",
      "|<Phyllis_Tickle>                 |<wordnet_writer_110794014>|\n",
      "|<Roger_McDonald>                 |<wordnet_writer_110794014>|\n",
      "|<es/Tomás_Lander>                |<wordnet_writer_110794014>|\n",
      "+---------------------------------+--------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combine source vertices and destination vertices\n",
    "v = destination_v.unionAll(source_v)\n",
    "\n",
    "# Define edges\n",
    "e = writers_df.withColumnRenamed(\"subject\",\"src\").withColumnRenamed(\"object\",\"dst\").select(\"src\",\"dst\")\n",
    "\n",
    "# Build graph\n",
    "g = GraphFrame(v, e)\n",
    "print(\"Graph: \"); print(g); print(\" \")\n",
    "print(\"Vertices: \"); g.vertices.show(5, False)\n",
    "print(\"Edges: \"); g.edges.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                   a|                   e|                   b|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|[<Carl_von_Ossiet...|[<Carl_von_Ossiet...|[<wordnet_writer_...|\n",
      "|[<Grazia_Deledda>...|[<Grazia_Deledda>...|[<wordnet_writer_...|\n",
      "|[<W._B._Yeats>, <...|[<W._B._Yeats>, <...|[<wordnet_writer_...|\n",
      "|[<Tjalling_Koopma...|[<Tjalling_Koopma...|[<wordnet_writer_...|\n",
      "|[<Henry_Yule>, <N...|[<Henry_Yule>, <w...|[<wordnet_writer_...|\n",
      "|[<Norman_Borlaug>...|[<Norman_Borlaug>...|[<wordnet_writer_...|\n",
      "|[<J._Michael_Kost...|[<J._Michael_Kost...|[<wordnet_writer_...|\n",
      "|[<Élie_Ducommun>,...|[<Élie_Ducommun>,...|[<wordnet_writer_...|\n",
      "|[<Nadine_Gordimer...|[<Nadine_Gordimer...|[<wordnet_writer_...|\n",
      "|[<Salvatore_Quasi...|[<Salvatore_Quasi...|[<wordnet_writer_...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Motif query\n",
    "motifs = g.find(\"(a)-[e]->(b)\")\n",
    "motifs.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of Nobel Prizes won by writers is: 255\n",
      "The number of writers who won Nobel Prizes is: 255\n"
     ]
    }
   ],
   "source": [
    "# Print the number of Nobel Prizes won by writers \n",
    "nobel_prizes_count = motifs.count()\n",
    "print(\"The number of Nobel Prizes won by writers is:\",nobel_prizes_count)\n",
    "\n",
    "# Check to see if any writers won multiple Nobel Prizes\n",
    "winners_count = motifs.select(\"a.id\").distinct().count()\n",
    "print(\"The number of writers who won Nobel Prizes is:\",winners_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+-------------------------------------------+\n",
      "|Name                          |Nobel Prize                                |\n",
      "+------------------------------+-------------------------------------------+\n",
      "|<14th_Dalai_Lama>             |<Nobel_Peace_Prize>                        |\n",
      "|<Adrienne_Clarkson>           |<Nobel_Prize_in_Physics>                   |\n",
      "|<Al_Gore>                     |<Nobel_Peace_Prize>                        |\n",
      "|<Albert_Camus>                |<Nobel_Prize_in_Literature>                |\n",
      "|<Albert_Einstein>             |<Nobel_Prize_in_Physics>                   |\n",
      "|<Albert_Lutuli>               |<Nobel_Peace_Prize>                        |\n",
      "|<Albert_Schweitzer>           |<Nobel_Peace_Prize>                        |\n",
      "|<Aleksandr_Solzhenitsyn>      |<Nobel_Prize_in_Literature>                |\n",
      "|<Alexander_Prokhorov>         |<Nobel_Prize_in_Physics>                   |\n",
      "|<Alexei_Alexeyevich_Abrikosov>|<Nobel_Prize_in_Physics>                   |\n",
      "|<Alexis_Carrel>               |<Nobel_Prize_in_Physiology_or_Medicine>    |\n",
      "|<Alfonso_García_Robles>       |<Nobel_Peace_Prize>                        |\n",
      "|<Alfred_Hermann_Fried>        |<Nobel_Peace_Prize>                        |\n",
      "|<Alfred_Kastler>              |<Nobel_Prize_in_Physics>                   |\n",
      "|<Alice_Munro>                 |<Nobel_Prize_in_Literature>                |\n",
      "|<Alva_Myrdal>                 |<Nobel_Peace_Prize>                        |\n",
      "|<Alvin_E._Roth>               |<Nobel_Memorial_Prize_in_Economic_Sciences>|\n",
      "|<Alvin_Toffler>               |<Nobel_Prize_in_Chemistry>                 |\n",
      "|<Amartya_Sen>                 |<Nobel_Memorial_Prize_in_Economic_Sciences>|\n",
      "|<Anatole_France>              |<Nobel_Prize_in_Literature>                |\n",
      "+------------------------------+-------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display a list of writers who have won Nobel Prizes (first 20 only)\n",
    "new_names = ['Name', 'Nobel Prize']\n",
    "motifs.select(\"a.id\",\"a.object\").orderBy('a.id').toDF(*new_names).show(20,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Nobel prize winners who were born in the same city as their spouses (Question E)\n",
    "You may find the predicate `'<isMarriedTo>'` useful to create a Dataframe of all mariages.\n",
    "Please also show the cities in which the Nobel laureates and their spouses were born.\n",
    "\n",
    "Please sort the output alphabetically by the person (prize winner) column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------+--------------------+-----+\n",
      "|                  id|             subject|    predicate|              object|value|\n",
      "+--------------------+--------------------+-------------+--------------------+-----+\n",
      "|<id_bv8wQjWcC7_?X...|<Edith_Killgore_K...|<isMarriedTo>|<Claude_Kirkpatrick>| null|\n",
      "|<id_eqxN5gR1iT_?X...|<Catherine_I,_Lat...|<isMarriedTo>|<Charles,_Count_o...| null|\n",
      "|<id_ANxEYVaN8C_?X...|<John_Frederick,_...|<isMarriedTo>|<Erdmuthe_of_Bran...| null|\n",
      "|<id_0UpPzpyhgL_?X...|        <Max_Frisch>|<isMarriedTo>|<Gertrud_Frisch-v...| null|\n",
      "|<id_h!AfjiGNcx_?X...|          <Chae_Rim>|<isMarriedTo>|    <Lee_Seung-hwan>| null|\n",
      "+--------------------+--------------------+-------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+--------------------+-------------+--------------------+-----+-------------+\n",
      "|                  id|             subject|    predicate|              object|value|        prize|\n",
      "+--------------------+--------------------+-------------+--------------------+-----+-------------+\n",
      "|<id_Fp0LhlXTCr_Yf...|  <Baruj_Benacerraf>|<hasWonPrize>|<Nobel_Prize_in_P...| null|<Nobel_Prize>|\n",
      "|<id_s252JUOzj2_Yf...|<Oliver_E._Willia...|<hasWonPrize>|<Nobel_Memorial_P...| null|<Nobel_Prize>|\n",
      "|<id_Dk!0PCE!6f_Yf...|        <Ilya_Frank>|<hasWonPrize>|<Nobel_Prize_in_P...| null|<Nobel_Prize>|\n",
      "|<id_mt5ZorALcK_Yf...|       <Martin_Ryle>|<hasWonPrize>|<Nobel_Prize_in_P...| null|<Nobel_Prize>|\n",
      "|<id_2zyoqbFz2K_Yf...| <Hamilton_O._Smith>|<hasWonPrize>|<Nobel_Prize_in_P...| null|<Nobel_Prize>|\n",
      "+--------------------+--------------------+-------------+--------------------+-----+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+--------------------+-----------+---------------+-----+\n",
      "|                  id|             subject|  predicate|         object|value|\n",
      "+--------------------+--------------------+-----------+---------------+-----+\n",
      "|<id_thPX9b1zg!_7f...|<William_Jones_(W...|<wasBornIn>|<Penrhiwceiber>| null|\n",
      "|<id_jj0mycL2ED_7f...|<Prince_Konrad_of...|<wasBornIn>|       <Vienna>| null|\n",
      "|<id_KPjIE3dH6?_7f...|    <Sean_Faircloth>|<wasBornIn>|<Bangor,_Maine>| null|\n",
      "|<id_jqUTrV8GuG_7f...|   <Beatrice_Welles>|<wasBornIn>|    <Manhattan>| null|\n",
      "|<id_etcRAp!dE4_7f...| <Paul_Sturzenegger>|<wasBornIn>|    <Argentina>| null|\n",
      "+--------------------+--------------------+-----------+---------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a subset of df including only individuals who have won prizes\n",
    "spouses_df = df.where(\"predicate == '<isMarriedTo>'\")\n",
    "\n",
    "# Add a new column to prize_winners_df called 'Nobel Prize'\n",
    "# NOTE: This dataset has already been filtered to include only nobel prize winners\n",
    "from pyspark.sql.functions import *\n",
    "prize_winners_df = prize_winners_df.withColumn(\"prize\",lit(\"<Nobel_Prize>\"))\n",
    "\n",
    "# Display the dataframes used for this question\n",
    "spouses_df.show(5)\n",
    "prize_winners_df.show(5)\n",
    "born_city_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices (name, <Nobel_Prize>): \n",
      "+----------------------------+-------------+\n",
      "|id                          |object       |\n",
      "+----------------------------+-------------+\n",
      "|<Werner_Forssmann>          |<Nobel_Prize>|\n",
      "|<Carl_von_Ossietzky>        |<Nobel_Prize>|\n",
      "|<Richard_R._Schrock>        |<Nobel_Prize>|\n",
      "|<Pierre_Curie>              |<Nobel_Prize>|\n",
      "|<Stanley_Cohen_(biochemist)>|<Nobel_Prize>|\n",
      "+----------------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Vertices (name, <isMarriedTo>): \n",
      "+--------------------------------------+-------------+\n",
      "|id                                    |object       |\n",
      "+--------------------------------------+-------------+\n",
      "|<Acamapichtli>                        |<isMarriedTo>|\n",
      "|<Adolf_William,_Duke_of_Saxe-Eisenach>|<isMarriedTo>|\n",
      "|<Agnes_of_Hesse>                      |<isMarriedTo>|\n",
      "|<Albert,_Duke_of_Prussia>             |<isMarriedTo>|\n",
      "|<Alexis_Bledel>                       |<isMarriedTo>|\n",
      "+--------------------------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Vertices (name, <wasBornIn>): \n",
      "+--------------------------+-----------+\n",
      "|id                        |object     |\n",
      "+--------------------------+-----------+\n",
      "|<Aargau>                  |<wasBornIn>|\n",
      "|<Abancay>                 |<wasBornIn>|\n",
      "|<Abbeville,_Louisiana>    |<wasBornIn>|\n",
      "|<Abilene,_Kansas>         |<wasBornIn>|\n",
      "|<Accoville,_West_Virginia>|<wasBornIn>|\n",
      "+--------------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define vertices (name, <Nobel_Prize>)\n",
    "prize_v = prize_winners_df.select(\"subject\",\"prize\").withColumnRenamed(\"subject\",\"id\").withColumnRenamed(\"prize\",\"object\").dropDuplicates([\"id\"])\n",
    "print(\"Vertices (name, <Nobel_Prize>): \"); prize_v.show(5, False)\n",
    "\n",
    "# Define vertices (name, <isMarriedTo>)\n",
    "marriage_v = spouses_df.select(\"subject\",\"predicate\").withColumnRenamed(\"subject\",\"id\").withColumnRenamed(\"predicate\",\"object\").dropDuplicates([\"id\"])\n",
    "print(\"Vertices (name, <isMarriedTo>): \"); marriage_v.show(5, False)\n",
    "\n",
    "# Define vertices (name, <wasBornIn>)\n",
    "city_v = born_city_df.select(\"object\",\"predicate\").withColumnRenamed(\"object\",\"id\").withColumnRenamed(\"predicate\",\"object\").dropDuplicates([\"id\"])\n",
    "print(\"Vertices (name, <wasBornIn>): \"); city_v.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph: \n",
      "GraphFrame(v:[id: string, object: string], e:[src: string, dst: string])\n",
      " \n",
      "Vertices: \n",
      "+--------------------------+-----------+\n",
      "|id                        |object     |\n",
      "+--------------------------+-----------+\n",
      "|<Aargau>                  |<wasBornIn>|\n",
      "|<Abancay>                 |<wasBornIn>|\n",
      "|<Abbeville,_Louisiana>    |<wasBornIn>|\n",
      "|<Abilene,_Kansas>         |<wasBornIn>|\n",
      "|<Accoville,_West_Virginia>|<wasBornIn>|\n",
      "+--------------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Edges: \n",
      "+-----------------------------------+------------------------------+\n",
      "|src                                |dst                           |\n",
      "+-----------------------------------+------------------------------+\n",
      "|<Edith_Killgore_Kirkpatrick>       |<Claude_Kirkpatrick>          |\n",
      "|<Catherine_I,_Latin_Empress>       |<Charles,_Count_of_Valois>    |\n",
      "|<John_Frederick,_Duke_of_Pomerania>|<Erdmuthe_of_Brandenburg>     |\n",
      "|<Max_Frisch>                       |<Gertrud_Frisch-von_Meyenburg>|\n",
      "|<Chae_Rim>                         |<Lee_Seung-hwan>              |\n",
      "+-----------------------------------+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combine all vertices\n",
    "v_temp = prize_v.unionAll(marriage_v)\n",
    "v = city_v.unionAll(v_temp)\n",
    "\n",
    "# Define marriage edges (name, spouse name)\n",
    "marriage_e = spouses_df.withColumnRenamed(\"subject\",\"src\").withColumnRenamed(\"object\",\"dst\").select(\"src\",\"dst\")\n",
    "\n",
    "# Define born city edges (name, city)\n",
    "city_e = born_city_df.withColumnRenamed(\"subject\",\"src\").withColumnRenamed(\"object\",\"dst\").select(\"src\",\"dst\")\n",
    "\n",
    "# Combine all edges\n",
    "e = marriage_e.unionAll(city_e)\n",
    "\n",
    "# Build graph\n",
    "g = GraphFrame(v, e)\n",
    "print(\"Graph: \"); print(g); print(\" \")\n",
    "print(\"Vertices: \"); g.vertices.show(5, False)\n",
    "print(\"Edges: \"); g.edges.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                   a|                   b|                   c|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|[<Otto_(singer)>,...|[<Alessandra_Negr...|[<Brazil>, <wasBo...|\n",
      "|[<Murilo_Benício>...|[<Alessandra_Negr...|[<Brazil>, <wasBo...|\n",
      "|[<Paerisades_III>...|[<Kamasarye_Philo...|[<Bosporan_Kingdo...|\n",
      "|[<Chris_Lazari>, ...|[<Maritsa_Lazari>...|[<Dora,_Cyprus>, ...|\n",
      "|[<Uzun_Hasan>, <i...|[<Shaykh_Haydar>,...|[<Despina_Khatun>...|\n",
      "|[<Catherine_Welle...|[<Arthur_Wellesle...|[<Dublin>, <wasBo...|\n",
      "|[<Said_Gafurov>, ...|[<Darya_Mitina>, ...|[<Moscow>, <wasBo...|\n",
      "|[<Mariota,_Counte...|[<Donald_of_Islay...|[<Scotland>, <was...|\n",
      "|[<Nurhayat_Hiçyak...|[<Erhan_Deniz>, <...|[<Turkey>, <wasBo...|\n",
      "|[<Brian_Grazer>, ...|[<Gigi_Levangie_G...|[<Los_Angeles>, <...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Motif query\n",
    "motifs = g.find(\"(a)-[]->(b); (a)-[]->(c); (b)-[]->(c)\")\n",
    "motifs.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+----------------------------------------+---------------------------------+\n",
      "|a                                       |b                                       |c                                |\n",
      "+----------------------------------------+----------------------------------------+---------------------------------+\n",
      "|[<Robert_Hofstadter>, <Nobel_Prize>]    |[<Douglas_Hofstadter>, <isMarriedTo>]   |[<New_York_City>, <wasBornIn>]   |\n",
      "|[<Carl_Ferdinand_Cori>, <Nobel_Prize>]  |[<Gerty_Cori>, <isMarriedTo>]           |[<Prague>, <wasBornIn>]          |\n",
      "|[<Al_Gore>, <Nobel_Prize>]              |[<Tipper_Gore>, <isMarriedTo>]          |[<Washington,_D.C.>, <wasBornIn>]|\n",
      "|[<Frédéric_Joliot-Curie>, <Nobel_Prize>]|[<Irène_Joliot-Curie>, <isMarriedTo>]   |[<Paris>, <wasBornIn>]           |\n",
      "|[<Irène_Joliot-Curie>, <Nobel_Prize>]   |[<Frédéric_Joliot-Curie>, <isMarriedTo>]|[<Paris>, <wasBornIn>]           |\n",
      "|[<Jimmy_Carter>, <Nobel_Prize>]         |[<Rosalynn_Carter>, <isMarriedTo>]      |[<Plains,_Georgia>, <wasBornIn>] |\n",
      "|[<Fridtjof_Nansen>, <Nobel_Prize>]      |[<Eva_Nansen>, <isMarriedTo>]           |[<Oslo>, <wasBornIn>]            |\n",
      "|[<Gerty_Cori>, <Nobel_Prize>]           |[<Carl_Ferdinand_Cori>, <isMarriedTo>]  |[<Prague>, <wasBornIn>]          |\n",
      "+----------------------------------------+----------------------------------------+---------------------------------+\n",
      "\n",
      "The number of nobel prize winners who were born in the same city as their spouses is: 8\n"
     ]
    }
   ],
   "source": [
    "# Filter out all extraneous rows\n",
    "motifs_new = motifs.filter(\"a.object == '<Nobel_Prize>' and b.object == '<isMarriedTo>' and c.object == '<wasBornIn>'\")\n",
    "motifs_new.show(10,False)\n",
    "\n",
    "# Print the number of nobel prize winners who were born in the same city as their spouses \n",
    "print(\"The number of nobel prize winners who were born in the same city as their spouses is:\",motifs_new.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-----------------------+------------------+\n",
      "|Prize Winner           |Spouse                 |Place of Birth    |\n",
      "+-----------------------+-----------------------+------------------+\n",
      "|<Al_Gore>              |<Tipper_Gore>          |<Washington,_D.C.>|\n",
      "|<Carl_Ferdinand_Cori>  |<Gerty_Cori>           |<Prague>          |\n",
      "|<Fridtjof_Nansen>      |<Eva_Nansen>           |<Oslo>            |\n",
      "|<Frédéric_Joliot-Curie>|<Irène_Joliot-Curie>   |<Paris>           |\n",
      "|<Gerty_Cori>           |<Carl_Ferdinand_Cori>  |<Prague>          |\n",
      "|<Irène_Joliot-Curie>   |<Frédéric_Joliot-Curie>|<Paris>           |\n",
      "|<Jimmy_Carter>         |<Rosalynn_Carter>      |<Plains,_Georgia> |\n",
      "|<Robert_Hofstadter>    |<Douglas_Hofstadter>   |<New_York_City>   |\n",
      "+-----------------------+-----------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print a list of all nobel prize winners who were born in the same city as their spouses\n",
    "new_names = ['Prize Winner', 'Spouse', 'Place of Birth']\n",
    "motifs_new.select(\"a.id\", \"b.id\", \"c.id\").orderBy('a.id').toDF(*new_names).show(motifs_new.count(),False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Politicians that are affiliated with a right-wing party (Question F)\n",
    "\n",
    "We are looking for all connections of the form `polician -> party`, where party is a right-wing party and politicians are defined above. If one politician is associated with several right wing parties, you may count them several times.\n",
    "\n",
    "Use `'<isAffiliatedTo>'` to find membership in organisations and `'<wikicat_Right-wing_parties>'` for right-wing parties organisations.\n",
    "\n",
    "There are multiple ways to do this.\n",
    "\n",
    "Please sort the output alphabetically by the person (politician) column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------+--------------------+-----+\n",
      "|                  id|             subject|predicate|              object|value|\n",
      "+--------------------+--------------------+---------+--------------------+-----+\n",
      "|<id_wGHfubCwBs_KC...|<Jean-Baptiste-Jo...| rdf:type|<wordnet_politici...| null|\n",
      "|<id_EQgbQobwPR_KC...|       <Reg_Freeson>| rdf:type|<wordnet_politici...| null|\n",
      "|<id_AZU1dcMWPB_KC...|       <Akbar_Ahmad>| rdf:type|<wordnet_politici...| null|\n",
      "|<id_OqLYLwYtOx_KC...|<it/Luigi_Di_Paol...| rdf:type|<wordnet_politici...| null|\n",
      "|<id_9bhVhwkbRF_KC...|<nl/William_Van_R...| rdf:type|<wordnet_politici...| null|\n",
      "+--------------------+--------------------+---------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+--------------------+---------+--------------------+-----+\n",
      "|                  id|             subject|predicate|              object|value|\n",
      "+--------------------+--------------------+---------+--------------------+-----+\n",
      "|<id_KParUhCo4d_KC...|<Institutional_De...| rdf:type|<wikicat_Right-wi...| null|\n",
      "|<id_fmIoHfvwcp_KC...|<Albanian_Alterna...| rdf:type|<wikicat_Right-wi...| null|\n",
      "|<id_SH6UcSI!qR_KC...|<North-East_Regio...| rdf:type|<wikicat_Right-wi...| null|\n",
      "|<id_K6zay7hUwe_KC...|<Monarchist_Allia...| rdf:type|<wikicat_Right-wi...| null|\n",
      "|<id_qjh7kSnz8e_KC...|<Green_Algeria_Al...| rdf:type|<wikicat_Right-wi...| null|\n",
      "+--------------------+--------------------+---------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+--------------------+----------------+--------------------+-----+\n",
      "|                  id|             subject|       predicate|              object|value|\n",
      "+--------------------+--------------------+----------------+--------------------+-----+\n",
      "|<id_tFZrF!JHzk_UI...|      <Willie_Logie>|<isAffiliatedTo>|<Alloa_Athletic_F...| null|\n",
      "|<id_G4qSWxcxWA_UI...|      <Nico_Zaldana>|<isAffiliatedTo>|<Feyenoord_Academ...| null|\n",
      "|<id_yiDMjTesE!_UI...|   <Augustus_Porter>|<isAffiliatedTo>|<Democratic-Repub...| null|\n",
      "|<id_EQiyS7snxh_UI...|<de/Mario_Neuhäuser>|<isAffiliatedTo>|<East_Germany_Oly...| null|\n",
      "|<id_x5jbLOrlim_UI...|       <Adrián_Ripa>|<isAffiliatedTo>|       <CD_Numancia>| null|\n",
      "+--------------------+--------------------+----------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a subset of df_subclasses including only politicians\n",
    "politician_df = df_subclasses.where(\"object == '<wordnet_politician_110450303>' and predicate == 'rdf:type'\")\n",
    "politician_df.show(5)\n",
    "\n",
    "# Create a subset of df_subclasses including only right-wing parties\n",
    "right_wing_df = df_subclasses.where(\"object == '<wikicat_Right-wing_parties>' and predicate == 'rdf:type'\")\n",
    "right_wing_df.show(5)\n",
    "\n",
    "# Create a subset of df which shows affiliations\n",
    "affiliation_df = df.where(\"predicate == '<isAffiliatedTo>'\")\n",
    "affiliation_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Vertices: \n",
      "+------------------------+------------------------------+\n",
      "|id                      |object                        |\n",
      "+------------------------+------------------------------+\n",
      "|<Abby_Lee_(politician)> |<wordnet_politician_110450303>|\n",
      "|<Abd_al-Karim_al-Jundi> |<wordnet_politician_110450303>|\n",
      "|<Abd_al-Majid_al-Rafei> |<wordnet_politician_110450303>|\n",
      "|<Abdul_Ali_Mazari>      |<wordnet_politician_110450303>|\n",
      "|<Abdul_Salam_al-Buseiri>|<wordnet_politician_110450303>|\n",
      "+------------------------+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Destination Vertices: \n",
      "+----------------------------------+----------------------------+\n",
      "|id                                |object                      |\n",
      "+----------------------------------+----------------------------+\n",
      "|<Alliance_of_Vojvodina_Hungarians>|<wikicat_Right-wing_parties>|\n",
      "|<Botswana_Democratic_Party>       |<wikicat_Right-wing_parties>|\n",
      "|<National_Democracy>              |<wikicat_Right-wing_parties>|\n",
      "|<National_Republican_Movement>    |<wikicat_Right-wing_parties>|\n",
      "|<New_Renaissance_Party>           |<wikicat_Right-wing_parties>|\n",
      "+----------------------------------+----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define source vertices (name, affiliation)\n",
    "source_v = politician_df.select(\"subject\",\"object\").withColumnRenamed(\"subject\",\"id\").dropDuplicates([\"id\"])\n",
    "print(\"Source Vertices: \"); source_v.show(5, False)\n",
    "\n",
    "# Define destination vertices (politician)\n",
    "destination_v = right_wing_df.select(\"subject\",\"object\").withColumnRenamed(\"subject\",\"id\").dropDuplicates([\"id\"])\n",
    "print(\"Destination Vertices: \"); destination_v.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph: \n",
      "GraphFrame(v:[id: string, object: string], e:[src: string, dst: string])\n",
      " \n",
      "Vertices: \n",
      "+----------------------------------+----------------------------+\n",
      "|id                                |object                      |\n",
      "+----------------------------------+----------------------------+\n",
      "|<Alliance_of_Vojvodina_Hungarians>|<wikicat_Right-wing_parties>|\n",
      "|<Botswana_Democratic_Party>       |<wikicat_Right-wing_parties>|\n",
      "|<National_Democracy>              |<wikicat_Right-wing_parties>|\n",
      "|<National_Republican_Movement>    |<wikicat_Right-wing_parties>|\n",
      "|<New_Renaissance_Party>           |<wikicat_Right-wing_parties>|\n",
      "+----------------------------------+----------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Edges: \n",
      "+--------------------+------------------------------------+\n",
      "|src                 |dst                                 |\n",
      "+--------------------+------------------------------------+\n",
      "|<Willie_Logie>      |<Alloa_Athletic_F.C.>               |\n",
      "|<Nico_Zaldana>      |<Feyenoord_Academy_(Varkenoord)>    |\n",
      "|<Augustus_Porter>   |<Democratic-Republican_Party>       |\n",
      "|<de/Mario_Neuhäuser>|<East_Germany_Olympic_football_team>|\n",
      "|<Adrián_Ripa>       |<CD_Numancia>                       |\n",
      "+--------------------+------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combine source vertices and destination vertices\n",
    "v = destination_v.unionAll(source_v)\n",
    "\n",
    "# Define edges\n",
    "e = affiliation_df.withColumnRenamed(\"subject\",\"src\").withColumnRenamed(\"object\",\"dst\").select(\"src\",\"dst\")\n",
    "\n",
    "# Build graph\n",
    "g = GraphFrame(v, e)\n",
    "print(\"Graph: \"); print(g); print(\" \")\n",
    "print(\"Vertices: \"); g.vertices.show(5, False)\n",
    "print(\"Edges: \"); g.edges.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                   a|                   e|                   b|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|[<István_Pásztor_...|[<István_Pásztor_...|[<Alliance_of_Voj...|\n",
      "|[<József_Kasza>, ...|[<József_Kasza>, ...|[<Alliance_of_Voj...|\n",
      "|[<de/Andor_Deli>,...|[<de/Andor_Deli>,...|[<Alliance_of_Voj...|\n",
      "|[<Sándor_Egeresi>...|[<Sándor_Egeresi>...|[<Alliance_of_Voj...|\n",
      "|[<Festus_Mogae>, ...|[<Festus_Mogae>, ...|[<Botswana_Democr...|\n",
      "|[<Ian_Khama>, <wo...|[<Ian_Khama>, <Bo...|[<Botswana_Democr...|\n",
      "|[<Nonofo_Molefhi>...|[<Nonofo_Molefhi>...|[<Botswana_Democr...|\n",
      "|[<Kitso_Mokaila>,...|[<Kitso_Mokaila>,...|[<Botswana_Democr...|\n",
      "|[<Pelonomi_Venson...|[<Pelonomi_Venson...|[<Botswana_Democr...|\n",
      "|[<Ponatshego_Kedi...|[<Ponatshego_Kedi...|[<Botswana_Democr...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Motif query\n",
    "motifs = g.find(\"(a)-[e]->(b)\")\n",
    "motifs.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of politicians associated with a right-wing party (with duplicates) is: 32243\n",
      "The number of politicians associated with a right-wing party (no duplicates) is: 29928\n"
     ]
    }
   ],
   "source": [
    "# Make sure there are no extraneous rows\n",
    "politician_motifs = motifs.filter(\"a.object == '<wordnet_politician_110450303>' and b.object == '<wikicat_Right-wing_parties>'\")\n",
    "\n",
    "# Display the number of politicians associated with a right-wing party\n",
    "# NOTE: This number includes repeat counts for a single politician with more than one right-wing party affiliation\n",
    "print(\"The number of politicians associated with a right-wing party (with duplicates) is:\", politician_motifs.count())\n",
    "\n",
    "# Display the number of politicians associated with a right-wing party\n",
    "# NOTE: This number includes a single count for each politician (regardless if they have multiple right-wing party affiliations)\n",
    "politicians_count = politician_motifs.select(\"e.src\").distinct().count()\n",
    "print(\"The number of politicians associated with a right-wing party (no duplicates) is:\", politicians_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+--------------------------------------+\n",
      "|Name                           |Political Party Affiliation           |\n",
      "+-------------------------------+--------------------------------------+\n",
      "|<A.N.M._Ehsanul_Hoque_Milan>   |<Bangladesh_Nationalist_Party>        |\n",
      "|<A._A._Wijethunga>             |<United_National_Party>               |\n",
      "|<A._B._Colton>                 |<Republican_Party_(United_States)>    |\n",
      "|<A._C._Clemons>                |<Republican_Party_(United_States)>    |\n",
      "|<A._C._Gibbs>                  |<Republican_Party_(United_States)>    |\n",
      "|<A._C._Hamlin>                 |<Republican_Party_(United_States)>    |\n",
      "|<A._Clifford_Jones>            |<Republican_Party_(United_States)>    |\n",
      "|<A._Dean_Jeffs>                |<Republican_Party_(United_States)>    |\n",
      "|<A._F._M._Ahsanuddin_Chowdhury>|<Jatiya_Party_(Ershad)>               |\n",
      "|<A._G._Crowe>                  |<Republican_Party_(United_States)>    |\n",
      "|<A._Homer_Byington>            |<National_Union_Party_(United_States)>|\n",
      "|<A._Homer_Byington>            |<Republican_Party_(United_States)>    |\n",
      "|<A._J._M._Muzammil>            |<United_National_Party>               |\n",
      "|<A._J._McNamara>               |<Republican_Party_(United_States)>    |\n",
      "|<A._J._Ranasinghe>             |<United_National_Party>               |\n",
      "|<A._K._A._Firoze_Noon>         |<Bangladesh_Nationalist_Party>        |\n",
      "|<A._K._Patel>                  |<Bharatiya_Janata_Party>              |\n",
      "|<A._Linwood_Holton_Jr.>        |<Republican_Party_(United_States)>    |\n",
      "|<A._M._Starr>                  |<Republican_Party_(United_States)>    |\n",
      "|<A._Piatt_Andrew>              |<Republican_Party_(United_States)>    |\n",
      "+-------------------------------+--------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the first 20 politicians associated with a right-wing party (incl. duplicates)\n",
    "new_names = ['Name', 'Political Party Affiliation']\n",
    "politician_motifs.select(\"e.src\",\"e.dst\").orderBy('e.src', 'e.dst').toDF(*new_names).show(20,False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
